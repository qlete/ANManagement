\section{State of the art}
\label{sec:stateart}

To combine optimal investment and operational decision, many people have investigated the use of large multi-time-steps optimization models (\cite{zonal_int}, \cite{Baker2012OptimalIO}, \cite{paolone}).
The integration of uncertainty in optimization is usually done either in a robust way (\cite{LorcaSun}, \cite{adaptative}, \cite{BM2}) or using stochastic optimization (\cite{Oren}). 
The main challenge when using optimization for planning the network is that they usually quickly becomes intractable. 
To decrease the computation complexity, linear and convex relaxations have been proposed (\cite{Farivar_Relax1}, \cite{Farivar_Relax2}, \cite{BM1}) where computational cost is considerably reduced. 
The drawback is that the solutions proposed are not necessary feasible anymore. 
Feasibility can be recovered by solving a sequence of convex problems (\cite{Nali}). 

More recently, Markov Decision Processes (MDP) and Reinforcement Learning (RL) have been proposed to deal with uncertainty in optimal planning of electricity grids. 
A recent survey reviews the use of RL in power system operations and propose new perspectives for developing the field of research (\cite{RLSurvey}).

